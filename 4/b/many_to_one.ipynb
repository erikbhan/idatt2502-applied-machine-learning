{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LongShortTermMemoryModel(nn.Module):\n",
    "    def __init__(self, encoding_size, label_size):\n",
    "        super(LongShortTermMemoryModel, self).__init__()\n",
    "\n",
    "        self.lstm = nn.LSTM(encoding_size, 128)  # 128 is the state size\n",
    "        self.dense = nn.Linear(128, label_size)  # 128 is the state size\n",
    "\n",
    "    def reset(self):  # Reset states prior to new input sequence\n",
    "        zero_state = torch.zeros(1, 1, 128)  # Shape: (number of layers, batch size, state size)\n",
    "        self.hidden_state = zero_state\n",
    "        self.cell_state = zero_state\n",
    "\n",
    "    def logits(self, x):  # x shape: (sequence length, batch size, encoding size)\n",
    "        out, (self.hidden_state, self.cell_state) = self.lstm(x, (self.hidden_state, self.cell_state))\n",
    "        return self.dense(out.reshape(-1, 128))\n",
    "\n",
    "    def f(self, x):  # x shape: (sequence length, batch size, encoding size)\n",
    "        return torch.softmax(self.logits(x), dim=1)\n",
    "\n",
    "    def loss(self, x, y):  # x shape: (sequence length, batch size, encoding size), y shape: (sequence length, encoding size)\n",
    "        return nn.functional.cross_entropy(self.logits(x), y.argmax(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = [ #alphabetical order\n",
    "    [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],  # ' ' 00\n",
    "    [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],  # 'a' 01\n",
    "    [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],  # 'c' 02\n",
    "    [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],  # 'f' 03\n",
    "    [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],  # 'h' 04\n",
    "    [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],  # 'l' 05\n",
    "    [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],  # 'm' 06\n",
    "    [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],  # 'n' 07\n",
    "    [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],  # 'o' 08\n",
    "    [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],  # 'p' 09\n",
    "    [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],  # 'r' 10\n",
    "    [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],  # 's' 11\n",
    "    [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],  # 't' 12\n",
    "]\n",
    "\n",
    "e = [\n",
    "    [1., 0., 0., 0., 0., 0., 0.],  # '🎩' 13\n",
    "    [0., 1., 0., 0., 0., 0., 0.],  # '🐀' 14\n",
    "    [0., 0., 1., 0., 0., 0., 0.],  # '🐈' 15\n",
    "    [0., 0., 0., 1., 0., 0., 0.],  # '🏢' 16\n",
    "    [0., 0., 0., 0., 1., 0., 0.],  # '🧑‍🦰' 17\n",
    "    [0., 0., 0., 0., 0., 1., 0.],  # '🧢' 18\n",
    "    [0., 0., 0., 0., 0., 0., 1.],  # '🧒' 19\n",
    "]\n",
    "\n",
    "encoding_size = len(c)\n",
    "index_to_emoji = ['🎩', '🐀', '🐈', '🏢', '🧑‍🦰', '🧢', '🧒']\n",
    "index_to_char = [' ', 'a', 'c', 'f', 'h', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't']\n",
    "\n",
    "x_train = torch.tensor([\n",
    "    [[c[4]],    [c[1]], [c[12]],    [c[0]]],      # 'hat '\n",
    "    [[c[10]],   [c[1]], [c[12]],    [c[0]]],     # 'rat '\n",
    "    [[c[2]],    [c[1]], [c[12]],    [c[0]]],      # 'cat '\n",
    "    [[c[3]],    [c[5]], [c[1]],     [c[12]]],      # 'flat'\n",
    "    [[c[6]],    [c[1]], [c[12]],    [c[12]]],     # 'matt'\n",
    "    [[c[2]],    [c[1]], [c[9]],     [c[0]]],       # 'cap '\n",
    "    [[c[11]],   [c[8]], [c[7]],     [c[0]]],      # 'son '\n",
    "])\n",
    "\n",
    "y_train = torch.tensor([\n",
    "    [e[0], e[0], e[0], e[0]],\n",
    "    [e[1], e[1], e[1], e[1]],\n",
    "    [e[2], e[2], e[2], e[2]],\n",
    "    [e[3], e[3], e[3], e[3]],\n",
    "    [e[4], e[4], e[4], e[4]],\n",
    "    [e[5], e[5], e[5], e[5]],\n",
    "    [e[6], e[6], e[6], e[6]],\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LongShortTermMemoryModel(encoding_size, len(e))\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), 0.001)\n",
    "\n",
    "for epoch in range(500):\n",
    "    for i in range(len(x_train)):\n",
    "        model.reset()\n",
    "        model.loss(x_train[i], y_train[i]).backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🐈\n",
      "🐀\n",
      "🧒\n",
      "🧑‍🦰\n",
      "🧑‍🦰\n",
      "🧑‍🦰\n",
      "🎩\n",
      "🐈\n",
      "🎩\n",
      "🎩\n",
      "🎩\n",
      "🎩\n",
      "🐀\n",
      "🐀\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'argmax'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\erik\\dev\\ml\\idatt2502-applied-machine-learning\\4\\b\\many_to_one.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/erik/dev/ml/idatt2502-applied-machine-learning/4/b/many_to_one.ipynb#W6sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m user_input \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mEmoji search:\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/erik/dev/ml/idatt2502-applied-machine-learning/4/b/many_to_one.ipynb#W6sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mwhile\u001b[39;00m user_input \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mexit\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/erik/dev/ml/idatt2502-applied-machine-learning/4/b/many_to_one.ipynb#W6sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     run(user_input)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/erik/dev/ml/idatt2502-applied-machine-learning/4/b/many_to_one.ipynb#W6sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     user_input \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mEmoji search:\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32mc:\\Users\\erik\\dev\\ml\\idatt2502-applied-machine-learning\\4\\b\\many_to_one.ipynb Cell 5\u001b[0m in \u001b[0;36mrun\u001b[1;34m(arg)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/erik/dev/ml/idatt2502-applied-machine-learning/4/b/many_to_one.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m char \u001b[39min\u001b[39;00m arg:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/erik/dev/ml/idatt2502-applied-machine-learning/4/b/many_to_one.ipynb#W6sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     y \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mf(torch\u001b[39m.\u001b[39mtensor([[c[index_to_char\u001b[39m.\u001b[39mindex(char)]]]))\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/erik/dev/ml/idatt2502-applied-machine-learning/4/b/many_to_one.ipynb#W6sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m(index_to_emoji[y\u001b[39m.\u001b[39;49margmax()])\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'argmax'"
     ]
    }
   ],
   "source": [
    "def run(arg: str):\n",
    "    model.reset()\n",
    "    y = ''\n",
    "    for char in arg:\n",
    "        y = model.f(torch.tensor([[c[index_to_char.index(char)]]]))\n",
    "    print(index_to_emoji[y.argmax()])\n",
    "\n",
    "user_input = input(\"Emoji search:\")\n",
    "while user_input != \"exit\":\n",
    "    run(user_input)\n",
    "    user_input = input(\"Emoji search:\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
